"""
QuickPay Daily Metrics DAG

ë§¤ì¼ ìƒˆë²½ dbt ëª¨ë¸ ë¹Œë“œ â†’ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ â†’ ëŒ€ì‹œë³´ë“œ ë¦¬í”„ë ˆì‹œ
íŒŒì´í”„ë¼ì¸ íë¦„:
  dbt_staging â†’ dbt_mart â†’ quality_check â†’ dashboard_refresh â†’ daily_summary

Why Airflow?
â†’ í† ìŠ¤/í•€í…Œí¬ í™˜ê²½ì—ì„œëŠ” "ì •í™•í•œ ì‹œì ì— ì •í™•í•œ ë°ì´í„°"ê°€ í•µì‹¬.
  Cronìœ¼ë¡œëŠ” DAG ê°„ ì˜ì¡´ì„±, ì¬ì‹œë„, ì•Œë¦¼ ê´€ë¦¬ê°€ ë¶ˆê°€ëŠ¥.
  AirflowëŠ” ë°ì´í„° íŒŒì´í”„ë¼ì¸ì˜ "ì‹¤í–‰ ë³´ì¥"ì„ ì œê³µ.
"""

from datetime import datetime, timedelta

from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.operators.python import PythonOperator
from airflow.providers.slack.operators.slack_webhook import SlackWebhookOperator
from airflow.utils.trigger_rule import TriggerRule

# â”€â”€â”€ DAG ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
default_args = {
    "owner": "quickpay-dataops",
    "depends_on_past": False,
    "email": ["data-team@quickpay.io"],
    "email_on_failure": True,
    "email_on_retry": False,
    "retries": 2,
    "retry_delay": timedelta(minutes=5),
    "execution_timeout": timedelta(hours=1),
}

dag = DAG(
    dag_id="quickpay_daily_metrics",
    default_args=default_args,
    description="QuickPay ì¼ë³„ ì§€í‘œ ì§‘ê³„ íŒŒì´í”„ë¼ì¸",
    schedule_interval="0 2 * * *",  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=["quickpay", "daily", "metrics", "production"],
    max_active_runs=1,
)


# â”€â”€â”€ Task 1: dbt Staging ë¹Œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
dbt_staging = BashOperator(
    task_id="dbt_run_staging",
    bash_command=(
        "cd /opt/airflow/dbt/quickpay && "
        "dbt run --select staging --target prod "
        "--vars '{\"run_date\": \"{{ ds }}\"}'"
    ),
    dag=dag,
)

# â”€â”€â”€ Task 2: dbt Mart ë¹Œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
dbt_mart = BashOperator(
    task_id="dbt_run_mart",
    bash_command=(
        "cd /opt/airflow/dbt/quickpay && "
        "dbt run --select mart --target prod "
        "--vars '{\"run_date\": \"{{ ds }}\"}'"
    ),
    dag=dag,
)

# â”€â”€â”€ Task 3: dbt Test (ìŠ¤í‚¤ë§ˆ í…ŒìŠ¤íŠ¸) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
dbt_test = BashOperator(
    task_id="dbt_test",
    bash_command=(
        "cd /opt/airflow/dbt/quickpay && "
        "dbt test --target prod "
        "--vars '{\"run_date\": \"{{ ds }}\"}'"
    ),
    dag=dag,
)


# â”€â”€â”€ Task 4: Great Expectations ë°ì´í„° í’ˆì§ˆ ê²€ì¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _run_quality_checks(**context):
    """Airflow contextì—ì„œ í’ˆì§ˆ ê²€ì¦ ì‹¤í–‰."""
    from portfolio.data_quality.quality_runner import run_all_checks

    partition_date = context["ds"]
    results = run_all_checks(partition_date=partition_date)

    # XComìœ¼ë¡œ ê²°ê³¼ ì „ë‹¬
    context["ti"].xcom_push(key="quality_results", value=results)
    return results


quality_check = PythonOperator(
    task_id="data_quality_check",
    python_callable=_run_quality_checks,
    dag=dag,
)

# â”€â”€â”€ Task 5: Tableau ëŒ€ì‹œë³´ë“œ ë¦¬í”„ë ˆì‹œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
dashboard_refresh = BashOperator(
    task_id="dashboard_refresh",
    bash_command=(
        'curl -X POST "https://tableau.quickpay.internal/api/3.19/sites/quickpay/extracts" '
        '-H "X-Tableau-Auth: {{ var.value.tableau_token }}" '
        '-d \'{"extractRefreshRequest": {"datasource": {"id": "quickpay-daily-metrics"}}}\''
    ),
    dag=dag,
)


# â”€â”€â”€ Task 6: ì™„ë£Œ ì•Œë¦¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _build_summary_message(**context):
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ ë©”ì‹œì§€ ìƒì„±."""
    ds = context["ds"]
    quality_results = context["ti"].xcom_pull(
        key="quality_results", task_ids="data_quality_check"
    )

    total_checks = len(quality_results) if quality_results else 0
    passed = sum(1 for r in (quality_results or []) if r.get("success"))
    failed = total_checks - passed

    status = "âœ… ì •ìƒ" if failed == 0 else f"âš ï¸ {failed}ê±´ ì‹¤íŒ¨"

    return (
        f"ğŸ“Š *QuickPay Daily Metrics Pipeline ì™„ë£Œ*\n"
        f"â€¢ ì‹¤í–‰ì¼: {ds}\n"
        f"â€¢ ìƒíƒœ: {status}\n"
        f"â€¢ í’ˆì§ˆ ê²€ì¦: {passed}/{total_checks} í†µê³¼\n"
        f"â€¢ ëŒ€ì‹œë³´ë“œ: <https://tableau.quickpay.internal|í™•ì¸>"
    )


success_alert = SlackWebhookOperator(
    task_id="pipeline_success_alert",
    slack_webhook_conn_id="slack_data_alert",
    message=_build_summary_message,
    channel="#data-daily-summary",
    trigger_rule=TriggerRule.ALL_SUCCESS,
    dag=dag,
)

# ì‹¤íŒ¨ ì‹œ ì•Œë¦¼
failure_alert = SlackWebhookOperator(
    task_id="pipeline_failure_alert",
    slack_webhook_conn_id="slack_data_alert",
    message=(
        "ğŸš¨ *QuickPay Daily Metrics Pipeline ì‹¤íŒ¨*\n"
        "â€¢ ì‹¤í–‰ì¼: {{ ds }}\n"
        "â€¢ ì‹¤íŒ¨ Task: {{ task_instance.task_id }}\n"
        "â€¢ ë¡œê·¸: {{ task_instance.log_url }}"
    ),
    channel="#data-alert-critical",
    trigger_rule=TriggerRule.ONE_FAILED,
    dag=dag,
)


# â”€â”€â”€ DAG Dependencies â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
dbt_staging >> dbt_mart >> dbt_test >> quality_check >> dashboard_refresh
dashboard_refresh >> [success_alert, failure_alert]
